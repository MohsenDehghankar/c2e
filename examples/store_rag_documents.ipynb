{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22b66a8",
   "metadata": {},
   "source": [
    "# Store RAG Documents\n",
    "\n",
    "This notebook retrieves PubMed papers based on keywords and stores them for RAG context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b4419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "from helpers import pubmed\n",
    "from tqdm import tqdm\n",
    "from helpers import llm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d01d9",
   "metadata": {},
   "source": [
    "## Setup PubMed API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbf6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model = \"deepseek-r1:32b\"  # used for keywords\n",
    "host = \"localhost\"\n",
    "port = 11434\n",
    "\n",
    "client = llm.setup_ollama_client(host=host, port=port)\n",
    "pubmed.set_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3a4db",
   "metadata": {},
   "source": [
    "## Load Claims from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7e4823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 claims\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence_doc_id</th>\n",
       "      <th>evidence_label</th>\n",
       "      <th>evidence_sentences</th>\n",
       "      <th>cited_doc_ids</th>\n",
       "      <th>causal_result_raw</th>\n",
       "      <th>is_medical_causal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>40mg/day dosage of folic acid and 2mg/day dosa...</td>\n",
       "      <td>33409100</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[33409100]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>A breast cancer patient's capacity to metaboli...</td>\n",
       "      <td>24341590</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[24341590]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34</td>\n",
       "      <td>A deficiency of folate increases blood levels ...</td>\n",
       "      <td>11705328</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[11705328]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39</td>\n",
       "      <td>A diminished ovarian reserve does not solely i...</td>\n",
       "      <td>13497630</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[13497630]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>A high microerythrocyte count protects against...</td>\n",
       "      <td>18174210</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>[1 9]</td>\n",
       "      <td>[18174210]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              claim  \\\n",
       "Unnamed: 0                                                          \n",
       "7           12  40mg/day dosage of folic acid and 2mg/day dosa...   \n",
       "24          30  A breast cancer patient's capacity to metaboli...   \n",
       "29          34  A deficiency of folate increases blood levels ...   \n",
       "32          39  A diminished ovarian reserve does not solely i...   \n",
       "42          41  A high microerythrocyte count protects against...   \n",
       "\n",
       "            evidence_doc_id evidence_label evidence_sentences cited_doc_ids  \\\n",
       "Unnamed: 0                                                                    \n",
       "7                  33409100        SUPPORT                [8]    [33409100]   \n",
       "24                 24341590        SUPPORT               [10]    [24341590]   \n",
       "29                 11705328        SUPPORT                [4]    [11705328]   \n",
       "32                 13497630        SUPPORT                [7]    [13497630]   \n",
       "42                 18174210        SUPPORT              [1 9]    [18174210]   \n",
       "\n",
       "           causal_result_raw  is_medical_causal  \n",
       "Unnamed: 0                                       \n",
       "7                        Yes               True  \n",
       "24                       Yes               True  \n",
       "29                       Yes               True  \n",
       "32                       Yes               True  \n",
       "42                       Yes               True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataloader/scifact_medical_causal_claims.csv\", index_col=0)\n",
    "print(f\"Loaded {len(df)} claims\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f542",
   "metadata": {},
   "source": [
    "## Define Keyword Generation and Retrieval Functions\n",
    "\n",
    "This approach:\n",
    "1. Uses DeepSeek-R1 to generate 4 keywords for each claim\n",
    "2. First searches for papers using AND logic with the keywords\n",
    "3. If less than 10 papers found with AND, augments results with additional papers from OR search (avoiding duplicates)\n",
    "4. Returns up to 10 papers total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(claim, n_keywords=4, model=default_model, client=client):\n",
    "    \"\"\"\n",
    "    Generate keywords for a claim using LLM.\n",
    "\n",
    "    Args:\n",
    "        claim: The medical claim to generate keywords for\n",
    "        n_keywords: Number of keywords to generate (default: 4)\n",
    "        model: LLM model to use\n",
    "        client: Ollama client\n",
    "\n",
    "    Returns:\n",
    "        String with keywords separated by ' AND '\n",
    "    \"\"\"\n",
    "    response = llm.call_ollama(\n",
    "        model=model,\n",
    "        prompt=f\"Suggest me a set of keywords to search for finding scientific articles about the following claim: {claim}. Give just a simple list of {n_keywords} keywords, separated by commas with no further explanation.\",\n",
    "        client=client,\n",
    "    )\n",
    "\n",
    "    output = response.get(\"response\", \"\")\n",
    "\n",
    "    # Extract keywords after </think> tag if present (DeepSeek-R1 reasoning)\n",
    "    if \"</think>\" in output:\n",
    "        output = output.split(\"</think>\")[-1].strip()\n",
    "\n",
    "    # Split by comma and clean up\n",
    "    keywords = [kw.strip() for kw in output.split(\",\") if kw.strip()][:n_keywords]\n",
    "\n",
    "    # Join with AND for PubMed search\n",
    "    return \" AND \".join(keywords)\n",
    "\n",
    "\n",
    "def retrieve_papers_with_fallback(keywords, top_k=10):\n",
    "    \"\"\"\n",
    "    Retrieve papers from PubMed with augmentation strategy.\n",
    "\n",
    "    First searches with AND logic. If fewer than top_k papers are found,\n",
    "    augments the results with additional papers from OR search (avoiding duplicates).\n",
    "\n",
    "    Args:\n",
    "        keywords: String with keywords separated by 'AND' (e.g., \"diabetes AND insulin AND glucose\")\n",
    "        top_k: Target number of papers to retrieve (default: 10)\n",
    "\n",
    "    Returns:\n",
    "        List of PubMedPaper objects (up to top_k papers)\n",
    "    \"\"\"\n",
    "    # First attempt: Use AND logic\n",
    "    papers_and = pubmed.get_papers(keywords, top_k=top_k)\n",
    "\n",
    "    # If we got enough papers with AND, return them\n",
    "    if len(papers_and) >= top_k:\n",
    "        return papers_and[:top_k]\n",
    "\n",
    "    # Otherwise, augment with OR search\n",
    "    print(f\"  Found only {len(papers_and)} papers with AND logic\")\n",
    "\n",
    "    # Convert 'AND' to 'OR' for broader search\n",
    "    keywords_or = keywords.replace(\" AND \", \" OR \")\n",
    "    print(f\"  Augmenting with OR search: {keywords_or}\")\n",
    "\n",
    "    # Calculate how many more papers we need\n",
    "    needed = top_k - len(papers_and)\n",
    "\n",
    "    # Get more papers with OR search\n",
    "    papers_or = pubmed.get_papers(keywords_or, top_k=top_k + len(papers_and))\n",
    "\n",
    "    # Get PMIDs from AND search to avoid duplicates\n",
    "    and_pmids = {paper.pmid for paper in papers_and}\n",
    "\n",
    "    # Add papers from OR search that aren't already in AND results\n",
    "    augmented_papers = papers_and.copy()\n",
    "    for paper in papers_or:\n",
    "        if paper.pmid not in and_pmids:\n",
    "            augmented_papers.append(paper)\n",
    "            if len(augmented_papers) >= top_k:\n",
    "                break\n",
    "\n",
    "    print(f\"  Total papers after augmentation: {len(augmented_papers)}\")\n",
    "\n",
    "    return augmented_papers[:top_k]  # Ensure we return at most top_k papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186be171",
   "metadata": {},
   "source": [
    "## Retrieve and Store Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"claim\": [],\n",
    "    \"keywords\": [],\n",
    "    \"paper_ids\": [],  # List of PMIDs\n",
    "    \"concatenated_abstracts\": [],  # All abstracts joined together\n",
    "    \"num_papers\": [],  # Number of papers retrieved\n",
    "}\n",
    "\n",
    "claims = df[\"claim\"].tolist()\n",
    "\n",
    "for idx, claim in enumerate(tqdm(claims, desc=\"Processing claims\")):\n",
    "    print(f\"\\nProcessing claim {idx+1}/{len(claims)}\")\n",
    "    print(f\"Claim: {claim[:100]}...\")\n",
    "\n",
    "    # Generate keywords using DeepSeek-R1 (already returns keywords with AND separator)\n",
    "    keywords = get_keywords(claim, n_keywords=4, model=default_model, client=client)\n",
    "    print(f\"Generated keywords: {keywords}\")\n",
    "\n",
    "    # Retrieve papers with fallback strategy (AND first, then OR if needed)\n",
    "    papers = retrieve_papers_with_fallback(keywords, top_k=10)\n",
    "\n",
    "    # Extract PMIDs and abstracts\n",
    "    paper_ids = [paper.pmid for paper in papers]\n",
    "    abstracts = [paper.abstract for paper in papers]\n",
    "\n",
    "    # Concatenate all abstracts with separators\n",
    "    concatenated_abstracts = \"\\n\\n---\\n\\n\".join(\n",
    "        [f\"[PMID: {pmid}] {abstract}\" for pmid, abstract in zip(paper_ids, abstracts)]\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    results[\"claim\"].append(claim)\n",
    "    results[\"keywords\"].append(keywords)\n",
    "    results[\"paper_ids\"].append(\",\".join(paper_ids))  # Store as comma-separated string\n",
    "    results[\"concatenated_abstracts\"].append(concatenated_abstracts)\n",
    "    results[\"num_papers\"].append(len(papers))\n",
    "\n",
    "    print(f\"Retrieved {len(papers)} papers\")\n",
    "\n",
    "    # Small delay to avoid overwhelming the API\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\nRetrieval complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701cd3e",
   "metadata": {},
   "source": [
    "## Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "output_file = \"rag_documents.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")\n",
    "print(f\"Total claims processed: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56083f4b",
   "metadata": {},
   "source": [
    "## Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f525d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c6e86",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c860689",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of papers retrieved per claim:\")\n",
    "print(results_df['num_papers'].describe())\n",
    "print(f\"\\nClaims with less than 10 papers: {(results_df['num_papers'] < 10).sum()}\")\n",
    "print(f\"Claimes with exactly 10 papers: {(results_df['num_papers'] == 10).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060584ac",
   "metadata": {},
   "source": [
    "## Example: View one claim's retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ad31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first claim's information\n",
    "example_idx = 0\n",
    "print(f\"Claim: {results_df.iloc[example_idx]['claim']}\")\n",
    "print(f\"\\nKeywords: {results_df.iloc[example_idx]['keywords']}\")\n",
    "print(f\"\\nNumber of papers: {results_df.iloc[example_idx]['num_papers']}\")\n",
    "print(f\"\\nPaper IDs: {results_df.iloc[example_idx]['paper_ids']}\")\n",
    "print(f\"\\nConcatenated Abstracts (first 500 chars):\\n{results_df.iloc[example_idx]['concatenated_abstracts'][:500]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
