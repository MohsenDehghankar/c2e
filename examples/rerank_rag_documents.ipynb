{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c8102d",
   "metadata": {},
   "source": [
    "# Rerank RAG Documents\n",
    "\n",
    "This notebook reranks the retrieved PubMed abstracts and selects the top 3 most relevant ones for each claim using DeepSeek-R1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d8ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "from helpers import llm\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd00bd",
   "metadata": {},
   "source": [
    "## Setup LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71481723",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model = \"deepseek-r1:32b\"  # used for reranking\n",
    "host = \"localhost\"\n",
    "port = 11434\n",
    "\n",
    "client = llm.setup_ollama_client(host=host, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8943ac",
   "metadata": {},
   "source": [
    "## Load Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ba844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reports/rag_documents.csv\")\n",
    "print(f\"Loaded {len(df)} claims with retrieved documents\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142eeee",
   "metadata": {},
   "source": [
    "## Define Reranking Function\n",
    "\n",
    "This function asks DeepSeek-R1 to select the top 3 most relevant abstracts for each claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be247b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_abstracts(claim, concatenated_abstracts, model=default_model, client=client, top_k=3):\n",
    "    \"\"\"\n",
    "    Rerank abstracts using LLM to find the most relevant ones.\n",
    "    \n",
    "    Args:\n",
    "        claim: The medical claim\n",
    "        concatenated_abstracts: String with all abstracts concatenated\n",
    "        model: LLM model to use\n",
    "        client: Ollama client\n",
    "        top_k: Number of top abstracts to select (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (list of PMIDs, concatenated top abstracts)\n",
    "    \"\"\"\n",
    "    # Handle empty or NaN abstracts\n",
    "    if pd.isna(concatenated_abstracts) or not concatenated_abstracts or concatenated_abstracts.strip() == \"\":\n",
    "        return [], \"\"\n",
    "    \n",
    "    # Parse the concatenated abstracts to extract individual papers\n",
    "    papers = concatenated_abstracts.split(\"\\n\\n---\\n\\n\")\n",
    "    \n",
    "    # Create a numbered list for the LLM\n",
    "    papers_list = \"\"\n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        papers_list += f\"\\n{i}. {paper}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a scientific assistant tasked with identifying the most relevant research papers for a given medical claim.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Below are {len(papers)} abstracts from PubMed. Please analyze each abstract and select the top {top_k} most relevant ones that best address or relate to the claim above.\n",
    "\n",
    "Abstracts:\n",
    "{papers_list}\n",
    "\n",
    "Please respond with ONLY the numbers of the top {top_k} most relevant abstracts, separated by commas (e.g., \"1,5,8\"). Do not provide any explanation, just the numbers.\"\"\"\n",
    "    \n",
    "    response = llm.call_ollama(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        client=client,\n",
    "    )\n",
    "    \n",
    "    output = response.get(\"response\", \"\")\n",
    "    \n",
    "    # Extract numbers after </think> tag if present (DeepSeek-R1 reasoning)\n",
    "    if \"</think>\" in output:\n",
    "        output = output.split(\"</think>\")[-1].strip()\n",
    "    \n",
    "    # Extract numbers from the response\n",
    "    import re\n",
    "    numbers = re.findall(r'\\d+', output)\n",
    "    selected_indices = [int(n) - 1 for n in numbers[:top_k]]  # Convert to 0-indexed\n",
    "    \n",
    "    # Get the selected papers\n",
    "    selected_papers = [papers[i] for i in selected_indices if i < len(papers)]\n",
    "    \n",
    "    # Extract PMIDs from selected papers\n",
    "    selected_pmids = []\n",
    "    for paper in selected_papers:\n",
    "        pmid_match = re.search(r'\\[PMID: (\\d+)\\]', paper)\n",
    "        if pmid_match:\n",
    "            selected_pmids.append(pmid_match.group(1))\n",
    "    \n",
    "    # Concatenate selected abstracts\n",
    "    concatenated_top_abstracts = \"\\n\\n---\\n\\n\".join(selected_papers)\n",
    "    \n",
    "    return selected_pmids, concatenated_top_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf00291",
   "metadata": {},
   "source": [
    "## Rerank and Store Top 3 Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4300a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"claim\": [],\n",
    "    \"keywords\": [],\n",
    "    \"top3_paper_ids\": [],  # List of top 3 PMIDs\n",
    "    \"top3_abstracts\": [],  # Top 3 abstracts concatenated\n",
    "    \"num_selected\": [],  # Should always be 3 (or less if fewer papers available)\n",
    "}\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Reranking abstracts\"):\n",
    "    print(f\"\\nProcessing claim {idx+1}/{len(df)}\")\n",
    "    print(f\"Claim: {row['claim'][:100]}...\")\n",
    "    \n",
    "    # Rerank abstracts to get top 3\n",
    "    top_pmids, top_abstracts = rerank_abstracts(\n",
    "        claim=row['claim'],\n",
    "        concatenated_abstracts=row['concatenated_abstracts'],\n",
    "        model=default_model,\n",
    "        client=client,\n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[\"claim\"].append(row['claim'])\n",
    "    results[\"keywords\"].append(row['keywords'])\n",
    "    results[\"top3_paper_ids\"].append(\",\".join(top_pmids))\n",
    "    results[\"top3_abstracts\"].append(top_abstracts)\n",
    "    results[\"num_selected\"].append(len(top_pmids))\n",
    "    \n",
    "    print(f\"Selected top {len(top_pmids)} papers: {', '.join(top_pmids)}\")\n",
    "    \n",
    "    # Small delay to avoid overwhelming the API\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\nReranking complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64027b4b",
   "metadata": {},
   "source": [
    "## Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "output_file = \"reports/reranked_rag_documents.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")\n",
    "print(f\"Total claims processed: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069d266",
   "metadata": {},
   "source": [
    "## Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26287b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332e46c",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of papers selected per claim:\")\n",
    "print(results_df['num_selected'].describe())\n",
    "print(f\"\\nClaims with exactly 3 papers: {(results_df['num_selected'] == 3).sum()}\")\n",
    "print(f\"Claims with less than 3 papers: {(results_df['num_selected'] < 3).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a116773",
   "metadata": {},
   "source": [
    "## Example: View one claim's top 3 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first claim's information\n",
    "example_idx = 0\n",
    "print(f\"Claim: {results_df.iloc[example_idx]['claim']}\")\n",
    "print(f\"\\nKeywords: {results_df.iloc[example_idx]['keywords']}\")\n",
    "print(f\"\\nNumber of selected papers: {results_df.iloc[example_idx]['num_selected']}\")\n",
    "print(f\"\\nTop 3 Paper IDs: {results_df.iloc[example_idx]['top3_paper_ids']}\")\n",
    "print(f\"\\nTop 3 Abstracts (first 500 chars):\\n{results_df.iloc[example_idx]['top3_abstracts'][:500]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
